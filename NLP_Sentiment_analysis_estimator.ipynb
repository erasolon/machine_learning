{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./glove.6B.zip -d glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/amazon_cells_labelled.txt\", sep=\"\\t\",header=None)\n",
    "df2 = pd.read_csv(\"data/imdb_labelled.txt\", sep=\"\\t\",header=None)\n",
    "df3 = pd.read_csv(\"data/yelp_labelled.txt\", sep=\"\\t\",header=None)\n",
    "df = df.append(df2)\n",
    "df = df.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(df[0])\n",
    "y = df[1].to_numpy()\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "MAX_LENGTH = 300\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=MAX_LENGTH)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "REPEAT_SIZE = 100\n",
    "\n",
    "def train_input_fn():\n",
    "    return tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat(REPEAT_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "def test_input_fn():\n",
    "    return tf.data.Dataset.from_tensor_slices((X_test, y_test)).repeat(REPEAT_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('./glove/glove.6B.300d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    layer = Embedding(vocab_size, MAX_LENGTH, weights=[embedding_matrix], input_length=maxlen , trainable=False)(features)\n",
    "    layer = Bidirectional(LSTM(128, return_sequences=True))(layer)\n",
    "    layer = Bidirectional(LSTM(128))(layer)    \n",
    "    logits = tf.keras.layers.Dense(units=2)(layer) \n",
    "    \n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1, name=\"classes\"),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "     # Calculate Loss   \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)    \n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf1.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss = loss,\n",
    "            global_step = tf1.train.get_global_step()\n",
    "            )\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # Add evaluation metrics Evaluation mode\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf1.metrics.accuracy(\n",
    "            labels=labels,\n",
    "            predictions=predictions[\"classes\"]\n",
    "        )}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppozzz5wc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppozzz5wc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:classes = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], probabilities = [[0.491 0.509]\n",
      " [0.49  0.51 ]\n",
      " [0.486 0.514]\n",
      " [0.49  0.51 ]\n",
      " [0.49  0.51 ]\n",
      " [0.486 0.514]\n",
      " [0.49  0.51 ]\n",
      " [0.491 0.509]\n",
      " [0.486 0.514]\n",
      " [0.492 0.508]\n",
      " [0.49  0.51 ]\n",
      " [0.491 0.509]\n",
      " [0.486 0.514]\n",
      " [0.489 0.511]\n",
      " [0.49  0.51 ]\n",
      " [0.49  0.51 ]\n",
      " [0.49  0.51 ]\n",
      " [0.49  0.51 ]\n",
      " [0.489 0.511]\n",
      " [0.491 0.509]\n",
      " [0.489 0.511]\n",
      " [0.488 0.512]\n",
      " [0.489 0.511]\n",
      " [0.491 0.509]\n",
      " [0.486 0.514]\n",
      " [0.49  0.51 ]\n",
      " [0.491 0.509]\n",
      " [0.489 0.511]\n",
      " [0.49  0.51 ]\n",
      " [0.49  0.51 ]\n",
      " [0.492 0.508]\n",
      " [0.489 0.511]]\n",
      "INFO:tensorflow:loss = 0.6896523, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.34058\n",
      "INFO:tensorflow:classes = [0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1], probabilities = [[0.76  0.24 ]\n",
      " [0.064 0.936]\n",
      " [0.156 0.844]\n",
      " [0.958 0.042]\n",
      " [0.855 0.145]\n",
      " [0.002 0.998]\n",
      " [0.979 0.021]\n",
      " [0.947 0.053]\n",
      " [0.669 0.331]\n",
      " [0.022 0.978]\n",
      " [0.053 0.947]\n",
      " [0.004 0.996]\n",
      " [0.457 0.543]\n",
      " [0.765 0.235]\n",
      " [0.949 0.051]\n",
      " [0.017 0.983]\n",
      " [0.011 0.989]\n",
      " [0.03  0.97 ]\n",
      " [0.975 0.025]\n",
      " [0.058 0.942]\n",
      " [0.984 0.016]\n",
      " [0.933 0.067]\n",
      " [0.974 0.026]\n",
      " [0.001 0.999]\n",
      " [0.014 0.986]\n",
      " [0.001 0.999]\n",
      " [0.056 0.944]\n",
      " [0.97  0.03 ]\n",
      " [0.001 0.999]\n",
      " [0.891 0.109]\n",
      " [0.002 0.998]\n",
      " [0.003 0.997]] (293.623 sec)\n",
      "INFO:tensorflow:loss = 0.32911074, step = 101 (293.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.379912\n",
      "INFO:tensorflow:classes = [0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1], probabilities = [[0.998 0.002]\n",
      " [0.063 0.937]\n",
      " [0.001 0.999]\n",
      " [0.001 0.999]\n",
      " [0.002 0.998]\n",
      " [0.022 0.978]\n",
      " [0.993 0.007]\n",
      " [0.991 0.009]\n",
      " [0.997 0.003]\n",
      " [0.013 0.987]\n",
      " [0.984 0.016]\n",
      " [0.006 0.994]\n",
      " [0.006 0.994]\n",
      " [0.002 0.998]\n",
      " [0.005 0.995]\n",
      " [0.001 0.999]\n",
      " [0.907 0.093]\n",
      " [0.011 0.989]\n",
      " [0.989 0.011]\n",
      " [0.998 0.002]\n",
      " [0.986 0.014]\n",
      " [0.984 0.016]\n",
      " [0.997 0.003]\n",
      " [0.002 0.998]\n",
      " [0.998 0.002]\n",
      " [0.001 0.999]\n",
      " [0.003 0.997]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.002 0.998]\n",
      " [0.996 0.004]\n",
      " [0.001 0.999]] (263.213 sec)\n",
      "INFO:tensorflow:loss = 0.010307, step = 201 (263.214 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 217...\n",
      "INFO:tensorflow:Saving checkpoints for 217 into /tmp/tmppozzz5wc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 217...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-15T14:28:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppozzz5wc/model.ckpt-217\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 53.78174s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-15-14:29:03\n",
      "INFO:tensorflow:Saving dict for global step 217: accuracy = 0.813125, global_step = 217, loss = 0.5496051\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 217: /tmp/tmppozzz5wc/model.ckpt-217\n",
      "INFO:tensorflow:global_step/sec: 0.320004\n",
      "INFO:tensorflow:classes = [1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1], probabilities = [[0.    1.   ]\n",
      " [0.994 0.006]\n",
      " [0.    1.   ]\n",
      " [0.959 0.041]\n",
      " [0.    1.   ]\n",
      " [0.959 0.041]\n",
      " [0.01  0.99 ]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.96  0.04 ]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.969 0.031]\n",
      " [0.99  0.01 ]\n",
      " [0.994 0.006]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.994 0.006]\n",
      " [0.018 0.982]\n",
      " [0.    1.   ]\n",
      " [0.992 0.008]\n",
      " [0.727 0.273]\n",
      " [0.001 0.999]\n",
      " [0.    1.   ]\n",
      " [0.966 0.034]\n",
      " [0.    1.   ]\n",
      " [0.525 0.475]\n",
      " [0.    1.   ]\n",
      " [0.964 0.036]\n",
      " [0.    1.   ]] (312.496 sec)\n",
      "INFO:tensorflow:loss = 0.3794362, step = 301 (312.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.381395\n",
      "INFO:tensorflow:classes = [1 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0], probabilities = [[0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.994 0.006]\n",
      " [0.988 0.012]\n",
      " [0.983 0.017]\n",
      " [0.95  0.05 ]\n",
      " [0.009 0.991]\n",
      " [0.    1.   ]\n",
      " [0.002 0.998]\n",
      " [0.992 0.008]\n",
      " [0.    1.   ]\n",
      " [0.994 0.006]\n",
      " [0.001 0.999]\n",
      " [0.993 0.007]\n",
      " [0.    1.   ]\n",
      " [0.996 0.004]\n",
      " [0.992 0.008]\n",
      " [0.001 0.999]\n",
      " [0.035 0.965]\n",
      " [0.994 0.006]\n",
      " [0.994 0.006]\n",
      " [0.986 0.014]\n",
      " [0.001 0.999]\n",
      " [0.002 0.998]\n",
      " [0.994 0.006]\n",
      " [0.995 0.005]\n",
      " [0.    1.   ]\n",
      " [0.    1.   ]\n",
      " [0.005 0.995]\n",
      " [0.992 0.008]\n",
      " [0.992 0.008]\n",
      " [0.994 0.006]] (262.195 sec)\n",
      "INFO:tensorflow:loss = 0.0074155815, step = 401 (262.195 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 425...\n",
      "INFO:tensorflow:Saving checkpoints for 425 into /tmp/tmppozzz5wc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 425...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-15T14:38:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppozzz5wc/model.ckpt-425\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 59.92306s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-15-14:39:10\n",
      "INFO:tensorflow:Saving dict for global step 425: accuracy = 0.813125, global_step = 425, loss = 0.7096556\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 425: /tmp/tmppozzz5wc/model.ckpt-425\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmppozzz5wc/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-02-15T14:42:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmppozzz5wc/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 62.85618s\n",
      "INFO:tensorflow:Finished evaluation at 2021-02-15-14:43:44\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.8, global_step = 500, loss = 0.84808326\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /tmp/tmppozzz5wc/model.ckpt-500\n",
      "INFO:tensorflow:Loss for final step: 0.0018263394.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.8, 'loss': 0.84808326, 'global_step': 500}, [])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "my_estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, model_dir=model_dir)\n",
    "\n",
    "# Set up training logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\", \"classes\": \"classes\"}\n",
    "logging_hook = tf.estimator.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "# Build specification \n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=500, hooks=[logging_hook])\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn)\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    my_estimator,\n",
    "    train_spec,\n",
    "    eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
